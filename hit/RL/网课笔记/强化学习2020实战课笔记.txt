1.torch的梯度更新不会自动清零，需要每次更新前手动重置0
2.pytorch的hub模块： https://github.com/pytorch/hub
3.hub模块已有的模型： https://pytorch.org/hub/research-models
4.padding可以有效缓解卷积中边缘特征提取不充分的情况，中间的元素被卷积核利用的次数多而边缘的元素被利用的少
5.卷积的一些超参数：卷积核个数、卷积尺寸、是否填充、滑动窗口步长
6.卷积结果计算公式
7.max pooling在绝大多数任务中都比average pooling的效果好
8.DQN处理连续动作的方法：离散化，梯度上升，miu P和V线性代数，感觉miu这个方法和确定性策略网络一样输出的a=miu
9.resNet的基本思想是至少保证了加两层的效果不会变差，具体实现有不改变特征图个数的i模块和改变特征图个数的c模块
10.A3C采用多个worker可以降低样本相关性
11.迁移学习可以根据自己的数据集大小来设定别人的参数应该固定多少