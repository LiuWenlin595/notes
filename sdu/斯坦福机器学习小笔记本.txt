慕课网整理：
离线机器学习————批处理；在线机器学习。
机器学习典型应用：关联规则(啤酒纸尿裤)、聚类(用户细分)、朴素贝叶斯(垃圾邮件识别)、决策树(银行贷款信用分析)、ctr预估(关键字搜索的结果排列)、协同过滤(电商购买推荐)
机器学习算法分类：有监督学习、无监督学习、半监督学习；分类和回归、聚类、标注；生成模型(给出属于各类的概率)、判别模型(直接判断出属于哪一个类)
机器学习基本框架：确定目标(需求分析、数据、特征工程) -> 训练模型(定义模型、损失函数、优化算法) -> 模型评估(交叉验证、效果评估)


斯坦福机器学习公开课整理：
m：样本数量   n：x的特征数量   θ：权值(参数)向量

监督学习部分   2~8
学习理论部分   9~11
无监督学习部分   12~15
机器学习部分   16~20

第一节课：
1.监督学习：给出了一组"标准答案"(回归和分类)
2.无监督学习：没有标准答案，自己摸索(聚类)
3.强化学习：定义好的行为和坏的行为，通过学习型算法来获得更多的回报和更少的惩罚



第二节课：
1.使得损失函数最小的几种算法：批梯度下降算法(每次用全部的训练样本更改权值)，随机梯度下降算法(每次用一个训练样本更改权值)
2.梯度下降(上升)算法：  θ := θ -(+) α*(dJ/dθ)
3.损失函数乘以1/2的原因：方便梯度下降的求导
4.trace(A*B) = trace(B*A) ; trace(A) = trace(A^T) ; trace(A*B*A^T*C) = C*A*B + C^T*A*B^T
5.if f(A)=trace(A*B) then df/dA = B^T
6.▽(_θ)J = [dJ/dθ_0 ; dJ/dθ_1 ; dJ/dθ_2 ; ....... ; dJ/dθ_n]
7.令▽(_θ)J=零向量，利用迹和转置的一些性质，求得正规方程组X^T*X*θ=X^T*y，最终求出θ=(X^T*X)^(-1)*X^T*y，
	这是另一种通过线性代数求解最小二乘拟合问题J(θ)来获得θ的方法，避免了类似于梯度下降这样的迭代算法(推导见lecture2后半节)

	
	
第三节课：
1.两个点可以用一次函数完全拟合，三个点可以用二次函数，...七个点可以用六次函数，n个点可以用n-1次函数
2.非参数学习算法：参数的个数会随着训练集的大小线性增长
3.局部加权回归(loess)：一种非参数学习算法，想获得x点的数据，x附近区域的数据子集的参数权重大，离x远的数据子集的参数权重小
	这种方法可以更加注重对临近点的精确拟合，忽略那些离得较远的点的贡献，此方法对于大型数据集合的代价比较高
	( 一种权值函数的选择是指数衰减函数：W = exp(-(xi-x)^2/(2*ξ)),ξ控制了权值随距离下降的速率 )
4.为何要采用最小二乘作为损失函数：在假设误差项满足高斯分布且独立同分布的情况下，使似然性l(θ)最大化就是要求损失函数J(θ)最小(推导见lecture3中间部分)
	推导过程中的方差σ对于似然性取得最大值时的θ不影响，会影响似然值l(θ)的结果大小
5.logictic算法：sigmoid函数，h_(θ)(x)=g(θ^T*x)=1/(1+e^(-θ^T*x)) ，y取值(0或1)的概率P(y|x;θ)=(h_(θ)x)^y*(1-h_(θ)x)^(1-y)
	具体做法是采用极大似然函数取对数后对θ求导，通过梯度上升算法求得l(θ)取得极大值的θ，此结果θ可被认为是最优参数(因为此时l(θ)取得极大值，意味着概率最大)
6.感知器算法(完全的二分化)：h_(θ)(x) = g(θ^T*x) = 1 if θ^T*x>0  else 0



第四节课：
1.牛顿方法：目标是l'(θ)=0。一维 θ(t+1) = θ(t) - l'(θ(t))/l"(θ(t))或(f(θ)/f'(θ))  /  多维 θ(t+1) = θ(t) - H^(-1)*▽_(θ)J  其中H_ij = d^2(l(θ))/(dθi*dθj)
	牛顿方法相比于批梯度下降算法，收敛速度快了很多，缺点是每次迭代要重新计算H会造成一定代价(H是n*n或n+1*n+1矩阵，n是x的特征数量)
2.二次收敛：算法的收敛速度成二次型(很快)
3.指数分布族：概率表达式满足P(y;η) = b(y)*exp(η^T*T(y)-a(η))    η:分布的自然参数   T(y):充分统计量
4.广义线性模型(GLM)：提供了一种解决机器学习问题的框架。当遇到一个新问题时，只需要选择概率分布函数(如伯努利分布)，其余步骤按照GLM顺着走就可以了
	(1) P(y|x;θ) 满足指数分布族		(2) 给定输入x 求输出h_(θ)(x) = E[T(y)|x;θ]		(3) 设定η=θ^T*x(η与x成线性关系)
5.正则响应函数：g(η) = 1/1+e^(-η)      正则关联函数：g(η)^(-1)    这俩函数作为了解，知道命名就可以
6.softmax回归：可以处理k类的分类问题，是一种基于多项式分布的广义线性模型，具体做法还是采用极大似然函数求导，根据求导结果进行梯度上升寻找l(θ)极大值的θ



第五节课：
1.判别学习模型：集中精力搞P(y|x)，重点是优化θ和h_(θ)(x)。形象理解是该算法求出目标x的极大似然结果y(h_(θ)(x))，从而对x分类。
2.生成学习模型：目标还是求P(y|x)，但利用贝叶斯公式，避免了θ的存在，而是集中精力搞P(x|y),P(y),P(x)。
	形象理解是该算法根据训练集y得出训练集x的分布(P(x|y))，通过判断目标x属于哪个分布，从而对x分类。
3.高斯判别分析(GDA)：首先要了解多元高斯分布以及公式，如果训练集x|y符合高斯分布，则P(x|y)可以通过高斯分布相关公式求得
	如果提前做出假设P(x|y=1)和P(x|y=0)服从相同的指数分布族(如高斯分布、泊松分布)，则可以推导出P(y=1|x)服从logistic回归。
	用高斯判别分析可以比logistic回归更好的利用数据，相应的，对假设前提以及样本数量会有一定要求
4.朴素贝叶斯算法：在该算法中，P(x1,x2,x3,..,xn|y)=Π(i从1到n的乘积) P(xi|y)   (朴素就是指假设xi之间互相独立，该假设使得该算法在属性相关性较大时效果不好) 
5.Leplace平滑：假设训练集中5个y都是0，对于下次的预测，如果不平滑的话P(y=1)=0/(0+5)=0，
	为了不使数据显得那么绝对，采用Leplace平滑，各项加1，P(y=1)=(0+1)/((0+1)+(5+1))=1/7。
	对于有k类的y，P(y=i)=(count(y=i)+1)/(m+k)
	

	
第六节课：
1.在本节课改变了一下模型的表示，h_(wb)(x) = g(W^T*x+b)   W是n维向量，b是一个实数，y取值为-1或1
2.函数间隔： ξi = yi*[W^T*xi+b]   ξ=min(ξi)   为控制函数间隔不能无脑大，可以采取正规化使‖W‖=定值
3.几何间隔： ξi = yi*[ W^T*xi/‖W‖ + b/‖W‖ ]   ξ=min(ξi)   几何间隔=函数间隔/‖W‖
4.几何间隔和函数间隔越大越好，这样不同类的数据离分界线更远，对类的区分更具有确定性
5.最大间隔分类器(支持向量机的前身)：选择特定的W和b，使得ξ(几何间隔)最大化，同时满足ξi >= ξ (ξ是函数间隔) (ξ=min(ξi))



第七节课：
1.KKT条件：用于解决拉格朗日乘数法的约束条件为不等式所假设的前提条件
2.支持向量：在求解min(W) f(W) = min(W) 1/2*‖W‖^2 (等价于max ξ/‖W‖) 且 s.t. ξi(函数间隔)>=ξ=1(预设ξ=1) 的问题中，约束条件为g(xi) = 1-ξi <= 0
	拉格朗日乘数法可知和KKT条件可知，L(W,b,μ) = f(W) + μg(x)且max(μ) L必须μg(x)=0，那些使得g(xi)=0(ξi(函数间隔)=1)而不用考虑μ的点，xi即为支持向量
	在KKT条件成立下，max(μ) min(W,b) L(W,b,μ) (拉格朗日对偶函数) = min(W,b) max(μ) L(W,b,μ) (拉格朗日函数) = min(W) f(W)
	支持向量包含着重构分割超平面的全部信息
3.支持向量机(SVM)：对于用于分类的支持向量机来说，给定一个包含正例和反例（正样本点和负样本点）的样本集合，支持向量机的目的是寻找一个超平面来对样本进行分割，
	把样本中的正例和反例用超平面分开，但是不是简单地分看，其原则是使正例和反例之间的间隔最大。
	通过原问题的对偶问题求对W和b的偏导得到W的解(W=Σμi*yi*xi)和b的约束条件(∑μi*yi=0)，再把得到的式子和约束带入原问题L求得μ，最后根据求得的μ求出W和b

	
	
第八节课：
1.核：在很多算法中用K(xi,xj)来代替<xi,xj>(xi和xj的内积)从而映射到更高维，K(x,z)=(x^T*z)^2=(∑i xi*zi)*(∑j xj*zj)= ∑i∑j (xi*xj)*(zi*zj) = φ(x)^T * φ(z)
	在线性不可分的情况下，核函数在低维上进行计算，而将实质上的分类效果表现在高维上，避免了高维空间的复杂计算，最终在高维特征空间中构造出最优分离超平面
	核函数K(x,z)的选择合理  等价于  核矩阵K_ij=K(xi,xj)是对称正半定函数
2.L1 norm软间隔SVM：对SVM进行了优化，使之可以处理非线性可分隔的情形(存在异常数据但整体线性可分隔)
	目标是 min(W,P) 1/2*‖W‖^2 + C*(Σ(i) Pi) ，其中P是一些惩罚项， s.t. ξi(函数间隔)>=1-Pi 且 Pi>=0
3.坐标上升法：对于目标min(a1,a2,...,an) W(a1,a2,...,an)，为了使得W取得最小值，进行这样的循环，
	while(未取得最小值) {
		for (i = 1:n) 
			ai := min(ai) W(a1,a2,...,an)};				
	即每次循环中在保证其他a不变的情况下只改变ai使得W最小，每次循环进行n次这样的操作，直到取得最小点
	这种方法所需的迭代次数较多，不过每次更改ai的代价很小
4.SMO算法(序列最小优化算法)：坐标上升法对于带有约束的问题不是普遍适用，SMO算法基于坐标上升法，每次会改变在不破坏约束前提下最小数量的ai
	每次的ai的选取可以采用启发式规则(经验法则)，关键步骤使如何在保证满足约束的情况下同步更改几个ai使W得到优化
	Ng讲解了针对两个ai的情况，首先利用约束条件把a1用a2表示出来，然后以a2作为自变量对W求最优解，这样就得到了一组a1a2，再看看是否符合其他约束来进行调整
	

	
第九节课：
1.偏差-方差权衡：选择合适的模型复杂度，保证既不能出现高偏差(欠拟合)，也不能出现高方差(过拟合)
	ε(h^) <= ε(h*) + 2*δ		h^表示H中 ε估(h) 最小的h， h*表示H中 ε(h) 最小的h
2.联合界引理(概率论一个常用定理)： P(A1∪A2∪...∪An) <= P(A1) + P(A2) + ... + P(An)  ，A1..An是事件，可以相互不独立，该定理可以用文氏图证明
3.Hoeffding不等式：z1...zm是独立同分布的随机变量，服从均值为φ的伯努利分布，φ估 = 1/m * Σzi
	Hoeffding不等式指的是P(|φ估-φ|>δ) <= 2*exp(-2*δ^2*m)，δ自己确定，这个式子保证了误差出现概率的上界。与切比雪夫不等式类似。
4.经验风险最小化(REM):使我的学习算法选择参数(θ)或选择函数(h_(θ)(x))以使得训练误差最小化，这样的话模型的一般误差也会最小
	关于该算法有效性的两个充分条件：
	1.证明训练误差是一般误差的一个很好的近似  ε估(h_j) = 1/m * ( Σ(i从1到m) ε(h_ij) ) = ε(h_j)，
	对于h_j函数，训练误差等于m个数据的一般误差求和的平均数，最后得到训练误差近似等于一般误差   
	2.证明对于函数集所有函数，一般误差与训练误差的差超过δ的概率存在上界(也称为一致收敛)(利用Hoeffding不等式和联合界引理结合)
	最后得出这个一致收敛的上界为k*2*exp(-2*δ^2*m) (H中有k个h函数)
	样本复杂度：为保证一个特定的出错概率的上界，所必需的训练集合或训练样本大小(固定δ改变m)

	
	
第十节课：
1.VC维：对于给定的假设类H，VC(H)=d 等价于 存在一个d个点的集合S，H能够分散S,但对于任何一个集合Y(其中Y集合的大小大于d),假设类H不能分散Y
	表示能够被H分散(区分)的打散(即不存在其中一个向量可以被另外的表示的情况)的最大样本集合的大小。	
	对于n维的线性假设器，其VC维是n+1
	想要最小话训练误差，需要的样本数量大概和假设类的VC维成线性关系，需要的模型参数数量大概和假设类的VC维相等。 
	也就是说，模型复杂度的上下界是由VC维给出的。超过下界无法解决问题或欠拟合，超过上界存在参数冗余或者过拟合
2.模型选择：
	保留交叉验证方法：将数据集分为两个子集，一个用作训练集，一个用作测试集，之后选择具有最小测试误差的模型
	k重交叉验证方法：进行k次交叉验证，每次训练集和测试集的选择可以不同，最后对k次得到的训练误差求平均值，选择具有最小测试误差的模型
	留1交叉验证：k=m的k重交叉验证，在第i次交叉验证中留第i个样本作为测试集，其余m-1个样本作为训练集。这方法在数据很少时才会用
3.特征选择：
	前向选择算法：初始化特征集F为空集，每次从n个特征中选择交叉验证效果最好的那个特征放入F，进行n次。
		相当于把n个特征根据优先级排了个序，然后再对排序后的特征集F做取舍之类的
		这是一种封装特征选择算法，即该算法封装在学习算法的外面，在执行该算法时需要重复的使用学习算法去训练模型
	后向选择算法：初始化特征集F为空集，然后根据一些算法从F中删特征，也是一种封装特征选择算法
	过滤特征选择算法：对于所有特征i，我们要设立一些衡量标准，来衡量对y的影响有多大
		衡量标准之一：计算特征xi和y的相关度，由大到小选取
		衡量标准之二：计算特征xi和y的相互信息KL(P(x,y)||P(x)*P(y))，相互信息是用来度量不同的概率分布之间的关联性的正规度量方式
		


第十一节课：
1.贝叶斯统计和规范化：在最大似然估计中参数θ被认为是常数，而贝叶斯规划将θ当作随机变量并给予了一个高斯分布的先验概率
	贝叶斯规划通过减小θ先验概率中高斯分布的方差来使得θ的值大多集中在0附近，从而实现图像平滑并克服过拟合
2.在线学习：对于每个训练数据，先预测结果然后通过和正确结果的对比来进行学习。而不是把所有训练集都学习完了再对测试数据预测。
3.学习算法的诊断调试法：
	高方差(过拟合)的表现：训练误差远远小于测试误差
	高偏差(欠拟合)的表现：训练误差和测试误差都会很高
	出现问题要判断解决方法是应该优化学习算法还是应该优化目标函数，存不存在过拟合和欠拟合
4.误差分析：将整个算法的每一部分组件分别替换为基准值，通过准确率的变化来判断哪部分组件运行效果不好(替换为基准值后准确率较之前变化得大)
5.销蚀分析：与误差分析相反，基于现有准确率每次去除一个组件，来观察准确率的变化，如果准确率变化小则说明该组件效果不大或不好
6.一些机器学习建议：不要过早优化



第十二节课：
1.K-means算法：首先初始化一组数据点，称之为类重心,这些类重心是我们对于每个类的中心的猜测
	按两步重复至模型收敛：	1.将数据集中所有数据分配给离它最近的类重心		2.根据每个类重心所分配的数据的平均值来更新类重心  
2.混合高斯模型：多个高斯分布函数的线性组合，是指同一集合下的数据是不同分布组合的情况
3.最大期望算法(EM)针对混合高斯模型求解：数据集里的每个数据没有标签，所以添加了一个隐含随机变量zi作为xi的标签，zi值的初始化是敏感的
	E-step：(求期望，更新zi)计算xi是第j类的期望概率P(zi=j|xi;θ)
	M-step：(求极大，更新θ)通过得到的期望概率，再结合监督学习里高斯判别分析的方法，进行收敛
4.Jensen不等式：对于凸函数，f(E(x)) >= E(f(x)) ； 对于凹函数，f(E(x)) <= E(f(x))
5.最大期望算法(EM)的一般形式：一种聚类算法
	E-step：选择Q(zi) = P(zi|xi;θ) ，这一步里根据当前θ并利用Jensen不等式会得到极大似然函数的下界
	M-step：根据一个和Q相关的式子对θ的值进行更新，以获得更高的下界
	//另一种理解EM的方式：L(θ)>=J(θ,Q) EM算法就是对J的坐标上升  在E-step中更新Q，在M-step中更新θ

	
	
第十三节课：
1.EM算法在混合贝叶斯模型的应用：还是那套EM步骤，具体公式结合朴素贝叶斯理解
2.因子分析算法：该算法可以进行高维数据下样本数据较少的情况下的模型拟合，主要采用了分块向量和分块矩阵的一些运算
	是一种密度分析算法，在训练实例有限的情况下试图模拟训练实例x的密度
	设定z~N(0,I) z∈R^d		x|z~N(μ+λz,ψ) 即等价于 x = μ+λz+ε 且 ε~N(0,ψ)		该模型参数为μ∈R^n,λ∈R^(n*d),ψ∈∈R^(n*n)且ψ为对角矩阵
	根据设定得 E(z)=0 E(x)=μ    定义一个新向量[z\nx]~N(μ_zx,Σ) 通过已知可以求得μ_zx = E(z\nx)=[0\nμ]   Σ是分块矩阵，比较复杂不写了
	之后运用EM算法
	E-step：  zi|xi ~ N(μ_zi|xi,Σ_zi|xi)  这个高斯分布的俩参数表示也挺复杂，这里不写了  		Q(zi) = P(zi|xi;θ)    
	M-step：  E(Q(zi))=μ_zi|xi， 通过更改参数来使得E(Q)最大化
		

		
第十四节课：
1.主成分分析(PCA)算法：一种降低数据维度的算法。       首先进行预处理：用数据的偏差除以标准差使数据标准化
	如果想用k维子空间近似表示xi，那么就要用n维向量θ来映射xi。 	主特征向量ui=(θ1^T*xi,θ2^T*xi,...,θk^T*xi)，是指最大k个特征值的对应特征向量
	主成分分析法总的思路是使得所有xi到ui的投影路径最短，直观理解是用更少数量特征的ui最大程度上近似表示xi的所有特征
	主成分分析的应用：数据可视化、数据压缩、简化计算、降低过拟合、异常数据检测(计算数据到子空间的投影长度)、图像处理

	
	
第十五节课：
1.奇异值分解(SVD)： A = U*D*V^T  		U的列是A*A^T的特征向量		V的列是A^T*A的特征向量
	可以将SVD运用于PCA，来减少计算数据的维度
2.独立成分分析(ICA)：ICA算法试图查找数据中的独立组成部分(例：把混合音分开)
	si表示每个人的声音(标签)，xi表示每个收音机接收的声音(原始数据)
	令P(s) = Π(n) P_s(si) 	那么P(x) = [Π(n) P_s(Wi*xi)]*|W|		x=A*s   W=A^(-1)   s=W*x
	算法进行首先需要给P_s()选择一个合适的概率密度函数，一般用sigmoid作为分布函数
	然后极大似然P(x)，求导，梯度下降W，用训练好的W进行s=W*x计算，最后求得s
	
	
	
第十六节课：
1.马尔可夫决策过程(MDP):
	MDP五元素：S状态；A动作；P_sa状态转换的概率函数；γ现贴因子(用来减小过长时间的状态的权重)；R奖励或惩罚
	p表示状态S所对应的策略，V^p(S)表示在策略p下状态S对应的值函数，V*(S)表示状态S在其最优策略下的值函数
	贝尔曼方程：V^p(S) = R(S) + γ* (∑(所有可能) P_sa(S')* V^p(S'))
				V*(S) = R(S) + max(A) γ* (∑(所有可能) P_sa(S')* V*(S'))     A的选择会影响不同的P_sa
	p*(S)表示状态S所对应的最优策略A   P*(S) = arg max(A) ∑(所有可能) P_sa(S')* V*(S') ，这个式子是从贝尔曼方程提取出了能影响A的选择的部分
	值迭代算法：初始化所有V(S)=0，然后while(不收敛) {for(每一个S)：V(S) := R(S) + max(A) γ* (∑(所有可能) P_sa(S')* V(S')) }
		这样最后可以得到每一个V(S)近似等于V*(S)，再用p*(S)求出状态S对应的最好的策略A
	策略迭代算法：初始化所有状态的策略，然后while(不收敛) {step1: for(每一个S)：V(S) := V^p(S)  ；
		step2: for(每一个S)：P*(S) = arg max(A) ∑(所有可能) P_sa(S')* V*(S') }
		这样最后P(S)会收敛到P*(S),V(S)也会收敛到V*(S)
	如何得到P_sa：测试，在策略p下状态S成功转到状态S’的次数/在策略p下状态S转换的次数
	零成本吸收状态：当进入某一状态后,没有更多回报,永远停留在该状态。
	


第十七节课：
1.MDP算法对状态离散不能很好地应对高维(会出现指数爆炸)，所以高维情况下要用连续的状态	
	V(S)=θ^T*φ(S)    V(S)是通过一组参数θ来近似的
	P*(S) = arg max(A) E( V(S') )		E( V(S') ) ≈ V( E(S') ) = V( f(S,A) ) = θ^T*φ(f(S,A))
2.近似值迭代算法：while(不收敛) {for(每一个S)：V(S) := R(S) + max(A) γ* E( V(S') )  其中S‘~P_sa }



第十八节课：
1.线性二次型法则(LQR)：主要特点是有限边界，目标是max R^0(s0,a0)+R^1(s1,a1)+...+R^t(st,at)
	其中S t+1 = A*st+B*at+ε   ε是一个高斯噪声,这样使f(st,at)可以非线性	    
	R^T(st,at) = -st^T*Ut*st - at^T*Vt*at    U、V是正半定矩阵
	Vt*(st) = max(at) R^T(st,at) 		Pt*(st) = arg max(at) R^T(st,at)
	还有balabala的一大堆没听懂，做了很多假设，定义了很多新式子，这算法可以解决无限大的连续状态空间的问题



第十九节课：
1.微分动态规划(DDP)：一种基于LQR的方法，好像是在不同的时间步中可以使用不同的状态转换函数
	(1)选定标称轨迹s0_, a0_, s1_, a1_, ... sT_, aT_
	(2)将在标称轨迹附近的点线性化，如s(t+1) = f(st_, at_)+(▽s f(st_, at_))^T*(st-st_)+(▽a f(st_, at_))^T*(at-at_) = Atst + Btat
		我们希望有(st, at) ≈ (st_, at_)
	(3)通过LQR算法获得πt
	(4)使用模拟器获得新的标称轨迹，即：s0_=initial state，at_ = π(st_)，st+1_ = f(st_, at_)
2.kalman滤波器：在只能通过观测而不能通过直接获得的情况下得到状态s
	没听懂啊没听懂



第二十节课：
1.策略搜索算法：
	Reinforced：定义P(si,ai)为si,ai情况下的策略函数，不断更新P即对P(si,ai)求导，进行随机梯度上升算法
	Pegasus：把状态转换函数理解为模拟器(黑盒子)，模拟器会产生一定的误差，即给定相同的状态和动作，每一次模拟器生成的结果都可能是不同的
			 为控制误差，每次生成一组固定的随机数序列放入模拟器，这样保证同一策略得出的结果相同(不会出现随机性的误差)，
			 这样的过程重复进行很多次，然后对全部次数的策略所拟合出的回报求平均

















	
	
	



















	
	


